{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c13525-afe5-4012-9c48-4f2ae3033f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import uproot\n",
    "import hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e4d4e-6a16-4506-a15f-6d22aaf6171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HEPHY topside\n",
    "x = np.arange(60, 86) #thr \n",
    "x = np.arange(174, 186) #HV 190-25\n",
    "x = np.concatenate((np.arange(174, 176),np.arange(177, 180),np.arange(181, 186))) #HV gefiltert\n",
    "\n",
    "# HEPHY backside\n",
    "x = np.arange(206, 231) #thr \n",
    "x = np.arange(234, 248) #HV 200-5\n",
    "x = np.arange(251, 256) #HV 450-250\n",
    "x = np.arange(271, 280) #HV 10-2\n",
    "x = np.concatenate((np.arange(234, 248), np.arange(251, 256), np.arange(271, 280))) #HV all\n",
    "\n",
    "# NIKHEF backside\n",
    "x = np.arange(308, 318) #HV 20-2\n",
    "x = np.arange(322, 332) #HV 500-50\n",
    "x = np.concatenate((np.arange(308, 318), np.arange(322, 332))) #HV all\n",
    "\n",
    "# Liverpool topside\n",
    "x = np.arange(342, 367) #thr\n",
    "x = np.arange(372, 466) #HV 500-50\n",
    "x = np.concatenate((np.arange(372, 410), np.arange(411, 437), np.arange(438, 466))) #HV 500-50 ohne error\n",
    "\n",
    "# NIKHEF backside_top\n",
    "x = np.arange(495, 507) #thr\n",
    "x = np.arange(468, 480) #HV 190-80\n",
    "x = np.arange(480, 494) #HV 70-5\n",
    "x = np.concatenate((np.arange(468, 480), np.arange(480, 494))) #HV all\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a09ab7e-0066-4663-8f57-946416b72b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use glob to find all files matching the pattern 'hv_vs_effi/logs/*log*.txt'\n",
    "logs = glob.glob('logfiles_old/*.log')\n",
    "\n",
    "# Initialize a dictionary 'effis' to store efficiency-related data\n",
    "effis = {'Efficiency': [], 'Err+': [], 'Err-':[], 'Bias':[]}\n",
    "run_map_file = '/home/harald/Desktop/MPW4/desy_04_24/all_data.csv'\n",
    "run_map = {}\n",
    "\n",
    "output_file = '/home/harald/Desktop/MPW4/desy_04_24/plots/effi_vs_threshold.png' #Select for threshold data\n",
    "plot_title = 'Efficiency vs. Threshold'\n",
    "x_label ='Threshold [mV]'\n",
    "\n",
    "# output_file = '/home/harald/Desktop/MPW4/desy_04_24/plots/effi_vs_bias.png'    #Select for HV data\n",
    "# plot_title = 'Efficiency vs. Bias'\n",
    "# x_label ='Bias [V]'\n",
    "\n",
    "\n",
    "#runs_to_analyse =  np.arange(174, 186)\n",
    "\n",
    "runs_to_analyse =  np.arange(495, 507)\n",
    "#ax_start = 30\n",
    "#ax_end = 102\n",
    "\n",
    "\n",
    "logs.sort()\n",
    "filesToRemove = []\n",
    "for r in logs:\n",
    "    match = re.search(r'analysis_jobsub_(\\d+)', r)\n",
    "    if match:\n",
    "        runNmb = int(match.group(1))\n",
    "        if not (runNmb in runs_to_analyse):\n",
    "            filesToRemove.append(r)\n",
    "    else:\n",
    "        filesToRemove.append(r)\n",
    "\n",
    "for f in filesToRemove:\n",
    "    logs.remove(f)\n",
    "\n",
    "with open(run_map_file) as f:\n",
    "    for line in f:\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        run, para = line.split(',')\n",
    "        run = int(run)\n",
    "        para = abs(float(para))\n",
    "        run_map[run] = para\n",
    "\n",
    "#run_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c88545-8a69-4ea0-b348-8bdddb64e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs.sort()\n",
    "\n",
    "# Loop through each file found by glob\n",
    "for f in logs:\n",
    "    with open(f) as log:  # Open the file for reading\n",
    "        for line in log:  # Loop through each line in the file\n",
    "\n",
    "            # Use regular expressions to search for a pattern in the line\n",
    "            # Explanation of the regex pattern:\n",
    "            # (?<=Total efficiency ) - Positive lookbehind for \"Total efficiency \"\n",
    "            # .+ - Match one or more of any character (except newline)\n",
    "            # (\\d\\d\\.\\d+) - Capture a numerical value in the format of two digits, a dot, and one or more digits (Efficiency)\n",
    "            # \\(.(0.\\d+) .(0.\\d+)' - Capture two numerical values in parentheses (Err+ and Err-)\n",
    "            match = re.search(r'(?<=Total efficiency )(.+(\\d\\d\\.\\d+)\\(.(0.\\d+) .(0.\\d+))', line)\n",
    "            #print(match)\n",
    "            \n",
    "            if not match:\n",
    "                continue  # If no match is found, skip to the next line\n",
    "\n",
    "            runNmb = int(re.search(r'analysis_jobsub_(\\d+)', f).group(1))\n",
    "            # Extract and store data based on the regular expression groups\n",
    "            effis['Bias'].append(run_map[runNmb])  # Extract 'Bias' from the file name\n",
    "            effis['Efficiency'].append(float(match.group(2)))  # Extract 'Efficiency' value\n",
    "            effis['Err+'].append(float(match.group(3)))  # Extract 'Err+' value\n",
    "            effis['Err-'].append(float(match.group(4)))  # Extract 'Err-' value\n",
    "\n",
    "df = pd.DataFrame(effis)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb9e610-c9f4-4d2e-8ca5-ee3cfde68137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of ROOT files to open\n",
    "root_file_list = glob.glob('/home/harald/Desktop/MPW4/desy_04_24/output/data_old/*.root')\n",
    "\n",
    "# Define a list of keys (TKeys) to extract data from\n",
    "#efficiency not working properly, TEfficiency sucks\n",
    "keys_to_extract = [[\"EventLoaderEUDAQ2/RD50_MPWx_base_0/hPixelRawValues\", \"ToT (LSB)\"],\n",
    "        [\"ClusteringSpatial/RD50_MPWx_base_0/clusterSize\", \"Cluster size\"],\n",
    "        [\"AnalysisDUT/RD50_MPWx_base_0/local_residuals/residualsX\", r\"Spatial Resolution X ($\\mu m$)\"],\n",
    "        [\"AnalysisEfficiency/RD50_MPWx_base_0/fake_rate/hFakePixelPerEvent\", \"Fake Rate\"]]\n",
    "\n",
    "run_map = {}\n",
    "\n",
    "x_name = 'Bias (mV)'\n",
    "\n",
    "root_file_list.sort()\n",
    "filesToRemove = []\n",
    "for r in root_file_list:\n",
    "    match = re.search(r'(\\d+)\\.root', r)\n",
    "    if match:\n",
    "        runNmb = int(match.group(1))\n",
    "        if not (runNmb in runs_to_analyse):\n",
    "            filesToRemove.append(r)\n",
    "    else:\n",
    "        filesToRemove.append(r)\n",
    "\n",
    "for f in filesToRemove:\n",
    "    root_file_list.remove(f)\n",
    "    \n",
    "root_file_list.sort()\n",
    "#root_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042e4698-dd83-4e52-b2b5-b2b7db307f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(run_map_file) as f:\n",
    "    for line in f:\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        run, para = line.split(',')\n",
    "        run = int(run)\n",
    "        para = abs(float(para))\n",
    "        run_map[run] = para\n",
    "\n",
    "#run_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ea91c7-ff2d-409f-81fe-872770e954b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store the results\n",
    "# results_df = pd.DataFrame(columns=[\"File\", \"Key\", \"Mean\", \"StdDev\"])\n",
    "results = {\"File\" : [], \"Key\" : [], \"Name\" : [], \"xVal\" : [], \"Mean\" : [], \"StdDev\": [], \"StdErr\" : [], \"N\" :[] }\n",
    "\n",
    "# Loop over each ROOT file\n",
    "for root_file in root_file_list:\n",
    "    # Open the ROOT file using uproot\n",
    "    with uproot.open(root_file) as file:\n",
    "        # Loop over each key to extract data\n",
    "        for key_name in keys_to_extract:\n",
    "            try:\n",
    "                # Access the TKey using the key name\n",
    "                tkey = file[key_name[0]]\n",
    "                # print(tkey)\n",
    "                mean_val = 0\n",
    "                std_dev_val = 0\n",
    "                N = 0\n",
    "                # Check if the TKey points to a TH1F histogram\n",
    "                if isinstance(tkey, uproot.uproot.behaviors.TH1.TH1):                    \n",
    "                    hist_np = tkey.to_numpy() # [0] ... bins, [1] ... weights\n",
    "                    # hist_data = tkey.to_hist()\n",
    "                    # hist_data.plot()\n",
    "                    # plt.show()\n",
    "                        \n",
    "                    unjagged_bins = (hist_np[1][:-1] + hist_np[1][1:]) / 2\n",
    "                    \n",
    "                    N = np.sum(hist_np[0])\n",
    "                    mean_val = np.sum(hist_np[0] * unjagged_bins) / N\n",
    "                    #print('mean = ', mean_val)                    \n",
    "                    std_dev_val = np.sqrt(np.sum(hist_np[0] * (unjagged_bins - mean_val)**2) / N)\n",
    "\n",
    "                    #hacky special treatment\n",
    "                    if 'hPixelRawValues' in key_name[0]:\n",
    "                        mask = unjagged_bins < 100\n",
    "                        N = np.sum(hist_np[0][mask])\n",
    "                        mean_val = np.sum(hist_np[0][mask] * unjagged_bins[mask]) / N\n",
    "                        std_dev_val = np.sqrt(np.sum(hist_np[0][mask] * (unjagged_bins[mask] - mean_val)**2) / N)\n",
    "                    #print('std', std_dev_val)\n",
    "                elif isinstance(tkey, uproot.uproot.behaviors.TProfile2D.TProfile2D):\n",
    "                    # print('encountered a', tkey)\n",
    "                    vals = tkey.values()\n",
    "                    # print(vals, np.average(vals))\n",
    "                    mean_val = np.average(vals)\n",
    "                    std_dev_val = np.std(vals)\n",
    "                    N = 1\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                runNmb = int(re.search(r'(\\d+)\\.root', root_file).group(1))\n",
    "                results[\"xVal\"].append(run_map[runNmb])\n",
    "                results[\"Mean\"].append(mean_val)\n",
    "                results['StdDev'].append(std_dev_val)\n",
    "                results['File'].append(root_file)\n",
    "                results['Key'].append(key_name[0])\n",
    "                results['Name'].append(key_name[1])\n",
    "                results[\"N\"].append(N)\n",
    "                results[\"StdErr\"].append(std_dev_val / np.sqrt(N))\n",
    "\n",
    "            except KeyError:\n",
    "                print(f\"Key '{key_name}' not found in file '{root_file}'\")\n",
    "\n",
    "df_root = pd.DataFrame(results)\n",
    "#df_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7087172a-8954-462b-9e19-0ca05c4647e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='Bias')\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "plt.title(\"Efficiency and Fake Rate vs. Bias voltage\")\n",
    "\n",
    "\n",
    "# Create the efficiency plot with error bars\n",
    "ax1.errorbar(df['Bias'], df['Efficiency'], yerr=[df['Err-'], df['Err+']], fmt='.', color='blue', markersize=8, capsize=5, label='Efficiency with Error Bars')\n",
    "ax1.set_xlabel(x_label)\n",
    "ax1.set_ylabel(r'$\\epsilon$(%)', color = 'blue')\n",
    "ax1.set_ylim(32,102)\n",
    "ax1.grid(True)\n",
    "\n",
    "# Annotate efficiency with Bias values\n",
    "# for i, row in df.iterrows():\n",
    "#     ax1.annotate(f'{row[\"Efficiency\"]:.2f}', (row['Bias'], row['Efficiency']), textcoords=\"offset points\", xytext=(5,5), ha='center')\n",
    "\n",
    "# Create plot for fake rate\n",
    "ax2 = ax1.twinx()\n",
    "i = 3\n",
    "key = ['AnalysisEfficiency/RD50_MPWx_base_0/fake_rate/hFakePixelPerEvent', 'Fake Rate']\n",
    "keyrows = df_root[df_root['Key'].str.contains(key[0])]\n",
    "x = keyrows['xVal'] \n",
    "y = keyrows['Mean']\n",
    "y = y/np.max(y) #Normierung Fake Rate\n",
    "# hacky special treatment\n",
    "if 'residuals' in key[0]:\n",
    "    y = keyrows['StdDev']\n",
    "yerr = df_root[df_root['Key'].str.contains(key[0])]['StdErr'].values\n",
    "\n",
    "#Plot Fake Rate with error bars\n",
    "ax2.set_ylabel(key[1]+' (a.u.)',color='green')\n",
    "ax2.errorbar(x, y, yerr=yerr, fmt='.', color='green', capsize=5)  # Add error bars\n",
    "ax2.set_ylim(bottom=0.2)\n",
    "\n",
    "#Create second x-axis\n",
    "ax3 = ax1.secondary_xaxis(\"top\")\n",
    "ax3.set_xticks(ax1.get_xticks())\n",
    "ax3.set_xbound(ax1.get_xbound())\n",
    "ax3.set_xticklabels([round((6.61133080e-06*np.power(x,3)-4.41590811e-03*np.power(x,2)+1.64285116e+00*x+8.25602665e+01)*2.8*6.242) for x in ax1.get_xticks()])\n",
    "#ax3.set_xticklabels([round((x * 0.809 + 120.71)*2.8*6.242) for x in ax1.get_xticks()]) #linear fit\n",
    "ax3.set_xlabel(\"Q (e)\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "fig.savefig(output_file)\n",
    "#fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c05c2-a36f-46cc-8d4b-12c5a9d1f1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b15f72e-5f38-4659-9851-49a855f1900c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78b65a9-5c55-4248-951a-335905e4a37f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
