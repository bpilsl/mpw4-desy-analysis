{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecfc7a0-573c-4b95-9e8b-5901699b7565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import hist\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c7ff0f-ee48-4b81-a66e-0bb61bf4abff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HEPHY topside\n",
    "x = np.arange(60, 86) #thr \n",
    "x = np.arange(174, 186) #HV 190-25\n",
    "\n",
    "# HEPHY backside\n",
    "x = np.arange(206, 231) #thr \n",
    "x = np.arange(234, 248) #HV 200-5\n",
    "x = np.arange(251, 256) #HV 450-250\n",
    "x = np.arange(271, 280) #HV 10-2\n",
    "\n",
    "# NIKHEF backside\n",
    "x = np.arange(308, 318) #HV 20-2\n",
    "x = np.arange(322, 332) #HV 500-50\n",
    "\n",
    "# Liverpool topside\n",
    "x = np.arange(341, 367) #thr\n",
    "x = np.arange(372, 466) #HV 500-50\n",
    "\n",
    "# NIKHEF backside_top\n",
    "x = np.arange(494, 507) #thr\n",
    "x = np.arange(468, 480) #HV 190-80\n",
    "x = np.arange(480, 494) #HV 70-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd598aaf-9bd7-4d47-a55a-3df9879599b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of ROOT files to open\n",
    "root_file_list = glob.glob('/home/harald/Desktop/MPW4/desy_04_24/output/data/*.root')\n",
    "\n",
    "# Define a list of keys (TKeys) to extract data from\n",
    "#efficiency not working properly, TEfficiency sucks\n",
    "keys_to_extract = [[\"EventLoaderEUDAQ2/RD50_MPWx_base_0/hPixelRawValues\", \"ToT (LSB)\"],\n",
    "        [\"ClusteringSpatial/RD50_MPWx_base_0/clusterSize\", \"Cluster size\"],\n",
    "        [\"AnalysisDUT/RD50_MPWx_base_0/local_residuals/residualsX\", r\"Spatial Resolution X ($\\mu m$)\"],\n",
    "        [\"AnalysisEfficiency/RD50_MPWx_base_0/fake_rate/hFakePixelPerEvent\", \"Fake Rate\"]]\n",
    "\n",
    "x_name = 'Bias (V)'\n",
    "# x_regex = r'(\\d\\d)V'\n",
    "output_file = '/home/harald/Desktop/MPW4/desy_04_24/output/nikhef_backside/bias_nikhef_back_characteristics_thr.svg'\n",
    "\n",
    "run_map_file = '/home/harald/Desktop/MPW4/desy_04_24/output/nikhef_backside/scan_mapping.csv'\n",
    "run_map = {}\n",
    "\n",
    "#runs_to_analyse = np.arange(342, 367)\n",
    "\n",
    "list1 = np.arange(308, 318)\n",
    "\n",
    "list2 = np.arange(322, 332)\n",
    "\n",
    "runs_to_analyse = np.concatenate((list1, list2))\n",
    "\n",
    "root_file_list.sort()\n",
    "filesToRemove = []\n",
    "for r in root_file_list:\n",
    "    match = re.search(r'(\\d+)\\.root', r)\n",
    "    if match:\n",
    "        runNmb = int(match.group(1))\n",
    "        if not (runNmb in runs_to_analyse):\n",
    "            filesToRemove.append(r)\n",
    "    else:\n",
    "        filesToRemove.append(r)\n",
    "\n",
    "for f in filesToRemove:\n",
    "    root_file_list.remove(f)\n",
    "    \n",
    "root_file_list.sort()\n",
    "root_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa94e6f7-c717-41e8-9c35-d2a1631b6ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(run_map_file) as f:\n",
    "    for line in f:\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        run, para = line.split(',')\n",
    "        run = int(run)\n",
    "        para = abs(float(para))\n",
    "        run_map[run] = para\n",
    "\n",
    "run_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b9c99-183e-43ef-8792-3b0bd35b32e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store the results\n",
    "# results_df = pd.DataFrame(columns=[\"File\", \"Key\", \"Mean\", \"StdDev\"])\n",
    "results = {\"File\" : [], \"Key\" : [], \"Name\" : [], \"xVal\" : [], \"Mean\" : [], \"StdDev\": [], \"StdErr\" : [], \"N\" :[] }\n",
    "\n",
    "# Loop over each ROOT file\n",
    "for root_file in root_file_list:\n",
    "    # Open the ROOT file using uproot\n",
    "    with uproot.open(root_file) as file:\n",
    "        # Loop over each key to extract data\n",
    "        for key_name in keys_to_extract:\n",
    "            try:\n",
    "                # Access the TKey using the key name\n",
    "                tkey = file[key_name[0]]\n",
    "                # print(tkey)\n",
    "                mean_val = 0\n",
    "                std_dev_val = 0\n",
    "                N = 0\n",
    "                # Check if the TKey points to a TH1F histogram\n",
    "                if isinstance(tkey, uproot.uproot.behaviors.TH1.TH1):                    \n",
    "                    hist_np = tkey.to_numpy() # [0] ... bins, [1] ... weights\n",
    "                    # hist_data = tkey.to_hist()\n",
    "                    # hist_data.plot()\n",
    "                    # plt.show()\n",
    "                        \n",
    "                    unjagged_bins = (hist_np[1][:-1] + hist_np[1][1:]) / 2\n",
    "                    \n",
    "                    N = np.sum(hist_np[0])\n",
    "                    mean_val = np.sum(hist_np[0] * unjagged_bins) / N\n",
    "                    #print('mean = ', mean_val)                    \n",
    "                    std_dev_val = np.sqrt(np.sum(hist_np[0] * (unjagged_bins - mean_val)**2) / N)\n",
    "\n",
    "                    #hacky special treatment\n",
    "                    if 'hPixelRawValues' in key_name[0]:\n",
    "                        mask = unjagged_bins < 100\n",
    "                        N = np.sum(hist_np[0][mask])\n",
    "                        mean_val = np.sum(hist_np[0][mask] * unjagged_bins[mask]) / N\n",
    "                        std_dev_val = np.sqrt(np.sum(hist_np[0][mask] * (unjagged_bins[mask] - mean_val)**2) / N)\n",
    "                    #print('std', std_dev_val)\n",
    "                elif isinstance(tkey, uproot.uproot.behaviors.TProfile2D.TProfile2D):\n",
    "                    # print('encountered a', tkey)\n",
    "                    vals = tkey.values()\n",
    "                    # print(vals, np.average(vals))\n",
    "                    mean_val = np.average(vals)\n",
    "                    std_dev_val = np.std(vals)\n",
    "                    N = 1\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                runNmb = int(re.search(r'(\\d+)\\.root', root_file).group(1))\n",
    "                results[\"xVal\"].append(run_map[runNmb])\n",
    "                results[\"Mean\"].append(mean_val)\n",
    "                results['StdDev'].append(std_dev_val)\n",
    "                results['File'].append(root_file)\n",
    "                results['Key'].append(key_name[0])\n",
    "                results['Name'].append(key_name[1])\n",
    "                results[\"N\"].append(N)\n",
    "                results[\"StdErr\"].append(std_dev_val / np.sqrt(N))\n",
    "\n",
    "            except KeyError:\n",
    "                print(f\"Key '{key_name}' not found in file '{root_file}'\")\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569f45dd-3e7f-4381-b794-623c0108d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_points(df, col_name):\n",
    "    for index, row in df.iterrows():\n",
    "        if col_name != row['Key']:\n",
    "            continue\n",
    "        x = row['xVal']\n",
    "        y = row['Mean']\n",
    "        val = f'{row[\"Mean\"]:.2f}'\n",
    "\n",
    "        # hacky special treatment\n",
    "        if 'residuals' in col_name:\n",
    "            y = row['StdDev']\n",
    "            val = f'{row[\"StdDev\"]:.2f}'\n",
    "        plt.annotate(val, (x, y), textcoords=\"offset points\", xytext=(10, 15), ha='center', fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c52d95-442a-47ee-9347-8a64a605778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Your existing code for creating subplots\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "for i, key in enumerate(keys_to_extract):\n",
    "    keyrows = df[df['Key'].str.contains(key[0])]  # Get sub dataframe where all rows containing the current key are in\n",
    "    plt.subplot(4, 1, i + 1)\n",
    "    \n",
    "    x = keyrows['xVal']\n",
    "    y = keyrows['Mean']\n",
    "    # hacky special treatment\n",
    "    if 'residuals' in key[0]:\n",
    "        y = keyrows['StdDev']\n",
    "    \n",
    "    yerr = df[df['Key'].str.contains(key[0])]['StdErr'].values\n",
    "    \n",
    "    # Plot a line plot with error bars\n",
    "    sns.lineplot(x=x, y=y, label='Data', marker='o')\n",
    "    plt.errorbar(x, y, yerr=yerr, fmt='.', color='blue', capsize=5)  # Add error bars\n",
    "    \n",
    "    plt.xlabel('')\n",
    "    plt.ylabel(key[1])\n",
    "    plt.title(key[1])\n",
    "    annotate_points(df, key[0])\n",
    "\n",
    "    # Add grid lines for both x-axis and y-axis in all subplots\n",
    "    plt.grid(True, which='both')\n",
    "\n",
    "    # Set y-ticks for all subplots\n",
    "    plt.gca().set_yticks(plt.gca().get_yticks())\n",
    "\n",
    "    ax = plt.gca()  # Get the current axis (last subplot)\n",
    "    ax.set_xticks(ax.get_xticks())  # This line refreshes the tick locations\n",
    "    ax.set_xticklabels(ax.get_xticks())  # Set tick labels to be the same as tick locations\n",
    "\n",
    "plt.xlabel(x_name)\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(output_file)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0e6ffc-a09f-4429-a06c-b81c68a4f8a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
